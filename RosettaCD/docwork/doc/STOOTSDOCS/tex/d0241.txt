R0241.tex
\documentstyle{Rosetta}
\begin{document}
   \RosTopic{General}
   \RosTitle{Machine Translation in Japan\\
            (Visit Report September 1987)}
   \RosAuthor{Jan Landsbergen}
   \RosDocNr{0241}
   \RosDate{November 12, 1987}
   \RosStatus{informal}
   \RosSupersedes{-}
   \RosDistribution{project}
   \RosClearance{Philips}
   \RosKeywords{}
   \MakeRosTitle
%


{\bf Abstract}

\bigskip

In this note an overview is given of the current Japanese 
activities in the field of machine
translation, mainly based on information gathered during my visit to Japan in
September 1987.

The main conclusion is that these activities are quite inpressive.
More than ten Japanese electronics firms have developed or are developing
an MT system for English to Japanese and/or Japanese to English. For seven firms
(Toshiba, Fujitsu, Hitachi, OKI, Sanyo, Sharp, NEC) 
this has already led to a commercial system.
Some firms are also developing modules for other European 
languages than English.
In addition several large government-sponsored projects on machine 
translation have started recently.
The linguistic quality of the developed systems is not high,
but due to their large
dictionaries and pleasant user-interfaces they may be useful anyway.

\newpage

\section{Introduction}

In September 1987 I visited a number of companies in Japan
which are active in the field of machine 
translation. In addition I attended the MT Summit Conference in Hakone.
This was not a scientific conference in the usual sense, its main
objective was to present the state of the art in MT, concentrating
on commercial systems, especially those developed by Japanese firms. 
The conference and
the visits together enabled me to get a fairly complete picture of
the extensive Japanese activities in this field, on which only
few publications in English are available.

This note is not a visit report in the strict sense. 
Instead of 
describing each visit and the information gathered there in
chronological order,
I prefer to give a somewhat more systematic - although superficial - 
description of the state of
the art in Machine Translation in Japan. 
However, for the record I will briefly discuss the visits in section 4.

In section 2 I will give my general impression of 
machine translation in Japan and make a comparison with the situation
at Philips.

In section 3 I will give an overview of the current machine translation
projects and systems in Japan.

In section 4 some references to recent publications will be given.

\bigskip

Throughout the paper I will use the following abbreviations:

MT = machine translation,

NL = natural language, 

NLP = natural language processing.

 
\section{General impression}

\subsection{Activities}

\bigskip

The main conclusion of the visit is that 
there is an enormous and still growing 
amount of research and development activity in the
field of machine translation,
both at private companies and at institutes sponsored by the Japanese 
 government. The industrial laboratories I visited usually had a language group
of 25 to 45 persons. More than ten
Japanese electronics firms 
(Toshiba, Fujitsu, Hitachi, OKI, Sanyo, Sharp, NEC, Ricoh, Canon, Mitsubishi,
Nippon-Data General, Matsushita, NTT) 
have recently developed or are now developing - separately -
an MT system for English to Japanese and/or Japanese to English. These
systems have large dictionaries (on the average a general dictionary of
50 000 words and a specialized dictionary with 50 000 to 250 000 words).
Occasionally systems are being developed for other European languages than
English. In addition to these separate industrial development activities
several large government-sponsored projects on MT, which will stimulate 
cooperation, have
started recently. In section 3 an overview of these activities and the
developed systems will be given. 

\subsection{Quality}


My impression about the quality of the translations is that it
is rather low and that in this respect there is not very much difference 
between the various systems. 
All the systems make use of some form of syntactic analysis,
which makes them better than earlier generations of MT systems, but
the syntactic analysis is rather superficial and this is one
of the reasons why the translations are often poor.
Most systems are intended to be used as an aid to a professional
translator, who may correct (`post-edit') 
the result, or to be used in a situation
where a low quality is acceptable. Some systems (e.g. Fujitsu's ATLAS system)
have also developed facilities
for interactive disambiguation or pre-editing (the pre-editor may help
to solve ambiguities by typing brackets).

Although the quality may be low from a linguistic point of view, 
the systems are considered useful, thanks to the large dictionaries and 
the pleasant user-interfaces.
For specialized technical texts the degree of ambiguity of words
is in general low and therefore the resulting translation may be
informative even if the sentences are ill-formed. 


During most of the visits and during the conference I had the opportunity
to see live demonstrations of the translation systems. 
It should be noted that it is not possible to evaluate an MT system by
means of a short demonstration. 
Most systems are tuned to a particular kind of texts, e.g.
abstracts of papers on information science. During the design of the system
a corpus of sample sentences from these texts is used: the quality of
the translations of the sentences of the corpus is used as a measure
for the improvement of the system. Most demonstrations
start with translating sentences from this corpus. 
The translations of these sentences are acceptable, although far from perfect.
However, this does not prove anything about the quality 
in case of sentences which are not in the corpus. 

Usually I had the opportunity to enter a few sentences myself (cf. section 4)
during the demonstrations. The results in that case were often disappointing
and were an indication that the grammars used in these systems are not
very sophisticated.
But it should be taken into account that these sentences were not from
the domain of texts to which the systems were tuned.


For a visitor without knowledge of Japanese it is impossible to evaluate
the quality of  English to Japanese translations, except if things go 
completely wrong, e.g. if the output contains the word ERROR 
between the Kanji characters. For Japanese to English the situation 
is better, because at least the output sentences can be judged for correctness.


For these reasons my personal impression about the linguistic quality of
the MT systems is necessarily superficial, but it was confirmed by
other researchers.

\bigskip

At the MT Summit conference there were preliminary 
reports by users of some of the systems. 

The Mazda Motor Corporation
uses Fujitsu's ATLAS system for increasing the efficiency
of their translation work. It is applied to the translation of
automobile service manuals.
Originally only 40 percent of the translations were good or correctable.
Then a joint project with Fujitsu was started to tune the grammars and
dictionaries to this application, which has already 
led to considerable improvement.

The Japan Patent Information Organisation tries to use Hitachi's
HICATS system for the translation of patents into English. The
preliminary conclusion is that up till now the quality is too low,
but that they will continue their efforts, together with the manufacturers
of MT systems, because there is no other feasible alternative for 
the solution of their translation problems.

A new and interesting way of using an MT system 
was reported to me by Roger Greatrex and Jon Sigurdson of the University
of Lund. They use the BRAVICE MT system in combination with a retrieval
system for abstracts of scientific papers. By entering English
keywords the user is able to get relevant Japanese abstracts and
their rough translation into English. They report that this system is
considered very useful.


\subsection{Public acceptance}


Because of the 
enormous translation problems, the 
Japanese public appears to have a positive attitude towards MT, even if the
quality is low. 
In this respect the situation in Europe may be a bit different.

The attractiveness of NLP applications for Japanese, including MT, has 
grown considerably, because typing Japanese characters has become easier. 
There are now cheap word processors that accept input in Kana (which consists
of 47 syllables and therefore can be typed on a normal keyboard)
and offer to the user the possible conversions into Kanji (the Chinese 
characters), enabling the user to enter a Kanji text in an interactive way.


\subsection{Translation strategy}


Most Japanese MT systems are transfer systems, i.e. they consist of an analysis
module for each source language, a transfer module for each language pair, 
and a generation module for each target 
language. Usually the interface between these modules is a kind
of dependency tree. In some projects an interlingual approach
is pursued, especially if one is interested in other languages than Japanese
and English, e.g. at Fujitsu.

Most systems aim at providing one unique translation fully automatically,
i.e. without involving the user in the translation process. The
output text has to be post-edited by a professional translator. 
This is usually called an interactive mode, but it should be noted
that here the interaction takes place after, not during, 
the translation process.

An exception is the TAURUS system which may give more than one translation,
in which case the (bi-lingual) user may indicate which one he chooses.


Usually the analysis component 
consists of two phases: in the first phase 
an augmented context-free grammar is used, in the second phase
case relations between, e.g., a verb and its arguments are 
established.

Dependency structures or deep case-like 
representations are problematic with respect to
the representation of, for example, scope and topicalisaton.
At the moment these phenomena are either neglected (e.g. in ATLAS) 
or a kind of mixed-level
representation is used (e.g. in the MU-system).  


To a certain extent the linguistic weakness of the systems 
is compensated by the size of
the dictionaries, which contain many compound terms. 

\bigskip

In order to arrive at a unique translation, the MT systems have to make
a decision in case of ambiguities. The chance that these decisions are
correct is higher if the system has some `knowledge of the world'.  
Most systems contain some world knowledge, usually 
represented in a rather straightforward way, e.g. by
means of semantic feature systems. NTT's LUTE system is the most interesting
exception,
it makes use of conceptual networks, but this has only been worked out for
a small dictionary. 

\subsection{Hardware/software requirements}

The systems run on a large variety of machines, from PCs to mainframes,
under various operating systems,
and have been implemented in a large variety of programming languages,
from Assembler to Prolog. For this kind of factual information I
refer to the tables in section 3. 

 

\subsection{Comparison between Philips and Japanese competitors} 


From a commercial point of view the situation is clear: most
Japanese electronics firms have a translation system on the market,
while Philips did not even start a development effort in this area.

However, Philips has a research project on MT, the Rosetta project,
in which experimental systems are developed.
If we try to compare our research 
with the state of the art in Japan, we see the following differences.

\bigskip
 
1. We have a somewhat different goal: 

(i) Other language pairs. Japanese - English is an extremely difficult
language pair, our research concentrates on Germanic and Romance languages,
which are more closely related. 

(ii) We follow an approach with
 interactive disambiguation, intended for monolingual users,
while most Japanese systems aim at post-editing by professional translators.
The main consequence of this for the research is that the linguistic 
quality of our systems must be very high, because the user is not able 
to correct the output, while on the other hand the knowledge of the 
world in the system, needed for disambiguation, may be restricted.  

\bigskip


2. The grammars we are currently developing in the Rosetta project 
are much more 
sophisticated than those used in the Japanese systems. 
This will yield a higher quality of 
translation.
There is no indication that current research in Japan will change
this situation drastically in the next few years. In my opinion the
Japanese underestimate the importance of a good linguistic model
in MT.

\bigskip

3. We lag behind in aspects that require not only research, but also
a large development effort, especially in the construction 
of large electronic dictionaries. Ultimately, these dictionaries are 
needed for research purposes too: it is not possible to test a
translation system on real texts without a large dictionary.


\section{Overview of MT activities in Japan}

\subsection{Companies}

There are seven companies with a commercial MT system for English to
Japanese and/or Japanese to English. These companies and their systems are:

\begin{verbatim}

Company:         System:

Toshiba          TAURAS                   
Fujitsu          ATLAS                     
Hitachi          HICATS (ATHENE)           
OKI              PENSEE                    
Sanyo            TWP                       
Sharp            SHARP MT                  
NEC              PIVOT (VENUS)             

\end{verbatim}

The Japanese firm BRAVICE International sells a translation aid for
Japanese to English (and to Korean) as
a software package. BRAVICE also sells
translation aids for the language pairs English to French, Spanish, German, 
Portuguese and Italian. BRAVICE has a majority share of Weidner
Communications Inc. Apparently these systems are versions of what used
to be known as the Weidner system. 

\bigskip

The Systran Corporation has developed 
a Japanese to English and English to Japanese 
version of the well-known SYSTRAN system. 

\bigskip


There are two Japanese companies with a translation system which
is not yet commercial, but in an advanced state of development.

\begin{verbatim}

Company:                  System:                   

Mitsubishi                MELTRAN
Ricoh                     RMT

\end{verbatim}


The following companies 
have started a considerable research/development effort in this area, but 
have not developed a full-fledged
translation system yet.

\begin{verbatim}

Company:                  System:

Matsushita                PAROLE                    
Canon                     LAMB
Nippon - Data General     MT
NTT                       LUTE

\end{verbatim}

Factual information about these systems, such as the language pairs, 
the size of the dictionaries,
the required equipment and the speed were provided by the companies 
at the MT Summit Conference
in table form. Copies of these tables are presented 
in section 3.3.


\subsection{Other projects}


{\bf Project MU II}

\bigskip

MU is the name of a large MT project that ran from 1982 until 1986 and that was led
by prof. Nagao of Tokyo University. The goal of the project was to develop
a system for the translation of abstracts of technical papers. The resulting
system is not in actual use, but a
successor project has started in 1986, which aims at developing a system which 
will be used at JICST (Japan Information Center for Science and Technology).
It is a again a 4-year
project headed by Nagao, in which 1600 million yen will be invested.

\bigskip
 

{\bf Japan and neighboring countries (ODA)}

\bigskip

Japan has organized a cooperative research project, together with
Thailand, Malaysia, Indonesia and China, named "Research
Cooperation on Machine Translation Systems with Japan's Neighboring Countries",
which will run from 1987 until 1992. 
The systems to be developed will have to translate industrial and
technical information between Japanese and Thai, Japanese and Malaysian,
Japanese and Indonesian, Japanese and Chinese. In a later
phase translation systems between Thai, Malaysian, Indonesian and Chinese
will be developed too.
Ultimately about 200 persons will be involved in this project.

\bigskip

{\bf Japanese Electronic Dictionary Research Institute (EDR)}

\bigskip

EDR is a large project for developing electronic 
dictionaries for Japanese, English, Japanese to English, English to Japanese,
and in addition so-called concept dictionaries in which word meanings and
meaning relations between them are made explicit. The project started in 1986. 
The ultimate goal, for 1994, is the
development of general dictionaries with 200 000 words and in addition
specialized terminology dictionaries (first for information science) with
100 000 words each.
This project is sponsored by the Japanese government (70 percent) and 8 Japanese
electronics firms (30 percent). The participating firms are Fujitsu, NEC, Hitachi,
Sharp, Toshiba, OKI, Mitsubishi and Matsushita. 

\bigskip

{\bf Advanced Telecom Research (ATR)}

\bigskip

ATR is a 15-year project (20 - 30 persons in the first phase), 
which started in 1986, 
with the ultimate goal to translate spoken
telephone conversation. In the first phase of the project (5 years)
one concentrates on translating simple sentences from a restricted
domain. 
The project is supported by the Japanese government, by NTT
and by a number of companies.

\newpage

{\bf Overview of Japanese MT systems}

\bigskip

{\bf Fujitsu}

\newpage

{\bf Hitachi}

\newpage

{\bf Kyoto University}

\newpage


{\bf NEC}

\newpage


{\bf OKI Industry}

\newpage

{\bf Ricoh}

\newpage

{\bf Sharp}

\newpage

{\bf Toshiba}

\newpage

{\bf Sanyo}

\newpage

{\bf CANON}

\newpage

{\bf Mitsubishi}

\newpage

{\bf Nippon - Data General}

\newpage

{\bf Matsushita}

\newpage

\section{Brief reports of visits}

The visits, which were excellently organized by dr. Hirai of
Philips Japan, usually had the following pattern: an introduction to the company
by the management, a discussion with a number of NLP researchers on
their current work, usually a demonstration of their system, and a presentation
about our own project, Rosetta. 

\subsection{Fujitsu}

Fujitsu Laboratories, Kawasaki.

Date: September 8, 1987

MT System: ATLAS.

Spoken with: Mr. Hiroshi Uchida (section manager Natural language processing),
Fumihito Nishino, Kenji Sugiyama, Yoshio Nakao, Yoshinobu Muta (collaborators
of machine translation project).

The NLP department consists of about 45 persons.
Research in this department includes natural language (Japanese) 
interfaces, intelligent 
information retrieval systems and automatic translation.

At the conference I heard rumours about a possible cooperation
between Siemens and Fujitsu on MT. Siemens is already active in MT for 
European languages
(German, English, French, Dutch).

\bigskip

Demonstration of ATLAS system:

Fujitsu develops not only Japanese and English, but
also French and German modules. After a short demonstration of the Japanese
to English system I got the opportunity to use the system for European
language pairs. 

\bigskip

English to French:

{\em Yesterday I went to bed early} \( \Rightarrow \) {\em De fa\c{c}on 
que t\^{o}t 
je suis all\'{e} au lit hier}

Obviously the system has a problem with the scope of the two time adverbials and
with the translation of {\em early}. Apparently it is interpreted as a manner
adverbial. 
 
The researchers were not satisfied with this output 
and called the Japanese to French system 
for the same sentence (i.e. its Japanese translation).
This was surprisingly translated into:

{\em Hier j'ai transper\c{c}\'{e} au plancher}.

\bigskip

French to English:

{\em Je l'ai promis}  \( \Rightarrow \)  {\em I promised him}

{\em J'ai promis de partir} \( \Rightarrow \) {\em I promised to start}

{\em Nous ne l'avions jamais fait} \( \Rightarrow \) {\em We had not done 
him with once=ichidomo}.

Apart from apparent problems with disambiguation, which may be
unsolvable in a fully automatic system, the 
last example shows that the system cannot handle the
double negation {\em ne ... jamais}  very well. This is probably caused
by shortcomings of the grammar.

The system uses `conceptual structures' as intermediate representation.
One of the problems with this kind of semantic representation is 
the representation of scope. This problem has been recognized, but not
been solved.

For lexical disambiguation the system makes use of a world model, which
contains information like {\em birds fly}, in the form of a conceptual
structure. A numerical value is associated with such a statement, 
indicating its plausibility or frequency or something like that. My
question about its exact nature caused a long discussion, partially
in Japanese, but there was no clear answer, except that it is
a pragmatic matter. 


\subsection{Hitachi}

Hitachi Advanced Research Laboratory, Tokyo

Date: September 9, 1987

Spoken with: Eiichi Maruyama (general manager), Yoshihiko Nitta (senior
researcher), Akihiro Hirai, mr. Motoyama, mr. Niwa, mr. Hisatsu.

The 
Advanced Research Laboratory currently employs 90 people, it will grow to 
200 people. It has the relaxed atmosphere of a real research environment.
Earlier research on MT by Nitta
(the ATHENE system) has been taken over by a development group and has led 
to the system HICATS. 
Nitta and his colleagues have returned to basic research. 
Among the topics studied are: the user interface
in an MT system with pre-editing, understanding of mathematical texts,
speech act theory, translation of mathematical texts into formal logic.

No demonstration could be given, but at the MT
Summit Conference HICATS was demonstrated. 


\subsection{NEC}

NEC Corporation: C and C Information Technology Research Laboratory, Kawasaki.

Date: September 10, 1987

MT system: VENUS

Spoken with: Kazumoto Iinuma (General manager), Kazunori Muraki 
(Research manager), Hideo Shimazu. 

The natural language group includes 18 persons working on MT and
story understanding and an unknown number involved in speech recognition.

Earlier MT work led to the VENUS system, which has been taken over by a
product division (under the name PIVOT), where especially the dictionaries 
were developed further and where currently a user test is going on.

A demonstration of the VENUS system had been planned, but failed completely
(no output at all). However at the MT Summit Conference the system was
successfully demonstrated.

\subsection{Kyoto University}

Kyoto University, Department of Electrical Engineering.

Date: September 11, 1987


MT system: MU 

Spoken with: prof. Makoto Nagao, dr. Jun-ichi Tsujii, dr. Jun-ichi Nakamura.

Prof. Nagao is generally accepted as the authority on MT in Japan. He has been 
active in the NLP field for 20 years. 
In 1980 he completed a system (called TITRAN)
which translated rather successfully titles of technical papers. From
1982 to 1986 he was the leader of the MU-project, developing a system 
for translating abstracts of technical papers. He will also 
lead the successor of the MU-project, a 4 year project
in which 1600 million Yen will be invested. (cf section 3).

Nakamura confirmed the rumour that it is very hard to improve the 
current MU system, mainly because of the complexity of the grammar,
which  is a program rather than a set of rules.


\bigskip


The English to Japanese MU-system was demonstrated.
First a listing of translations 
was shown of sentences from technical abstracts to which
the system has been tuned; these sentences were often long and complicated
and were translated fairly well.
For simple sentences that I suggested myself, the results were less
impressive. 

The input {\em The number of instruments increased considerably} (a simple 
variant of one of the sentences shown before) 
yielded incorrect output (it contained an error message). The problem appeared 
to be that {\em increased} was interpreted as a relative clause to 
{\em instruments}.

The translation of the sentence 
{\em We promised that we would leave} 
failed too. 
 
\bigskip

Kyoto University, Department of Information Science.

Spoken with: prof. Toyoaki Nishida and students.

Nishida has done research on MT a number of years ago, but is not involved in it
at the moment. The work currently done in his department is small-scale
AI-oriented research, mainly performed by students. 
Nishida also demonstrated his old MT system, but for unclear reasons it
did not perform as well as it should. An interesting aspect was that 
Tomita had built his interactive disambiguation system on top
of Nishida's system. 

\subsection{NTT}

Nippon Telephone and Telegraph Corporation
(Musashino Research Center)

Date: September 14, 1987

MT system: LUTE

Spoken with: dr. Hirosato Nomura (research group leader), Akira Shimazu.

Nomura stated that the main goal of his research is not the actual
development of translation systems 
(although several experimental
translation systems have been developed at NTT),  but
getting insight in natural language processing by humans, 
So it is fundamental research 
with an emphasis 
on knowledge representation, especially on developing a unified framework for
linguistic and non-linguistic knowledge. This aspect of the work
made a good impression to me. As far as the linguistic aspects are concerned,
the work is not more advanced than in other Japanese MT projects.

A short demonstration of the LUTE system was given, which showed how
a rather complicated Japanese sentence was analysed and ultimately
translated into English. 

Up till now there is no relation between this research and the Advanced
Telecom Project (cf section 3), in which NTT participates.

\subsection{Toshiba}

Toshiba Research and Development Center, Information Systems Lab.

Date: September 21, 1987

MT system: TAURUS

Spoken with: Kazuo Narita (manager research administration staff),
mr. Amano (leader of language group), mr. Masana Minami (senior manager 
Information Systems Lab.), dr. Teruhiko Ukita, dr. Harry Somers, mr. Kovichi
Hasebe, and others.

The language group (25 persons) consists of two parts: the MT group and
a group working on discourse analysis, in particular anaphora resolution
in a NL consultation system.

\bigskip
 
Demonstration:

After the usual demonstration of the translation of sentences from a
fixed corpus (of 2000 sentences), I had the opportunity to enter a few
sentences myself. I started with an example from a paper on TAURUS,
with {\em persuade + infinitive}, but this could not be handled.

In the TAURUS system much attention is paid to the translation of semi-idioms:
e.g. {\em take} in {\em I take a bath} must be translated
differently from {\em take} in {\em I take a bus}. The dictionary entry for
{\em take} contains the relevant information. However, when 
I entered the sentence {\em which bus should I take?},
{\em take} was not translated adequately. Presumably this was caused by
incorrect or incomplete syntactic analysis. After this the demonstrators
entered {\em This is the bus which I should take}, which was translated
correctly.


\subsection{Matsushita}

Matsushita Electrical Industrial Co., Tokyo Systems Research Department.

Date: September 22, 1987


Spoken with: mr. Masato Yamazaki (general manager), mr. Katsuhiro Komorida
(leader Natural Language Processing group), mr. Masaki Kiyono, mr. Yasukawa,
and others.

The Systems Research Department is rather new; currently it consists of 37 
people, but it is growing fast. There are two groups: a Natural Language 
Processing group and a Knowledge Based Systems group.

Matsushita started later with research on NLP than most other Japanese
electronics firms. It does not have a commercial MT system yet, but has started
research on MT recently. It participates in the EDR project (cf. section 3).
Other research topics in the NLP group are: 
conversational interfaces (applied to
the generation of patent descriptions),
text understanding (in particular anaphora resolution, to be applied in MT 
systems). It is the intention 
to base this work on situation semantics and unification 
grammar. 

\section{Literature}

An overview of the Japanese MT activities is given in:

\bigskip

Nishida T. and S. Doshita, {\em 
Machine translation: Japanese perspectives}.
In: Picken, Catronia (ed.), Translating and the Computer, proceedings of
Aslib Conference, November 1985, London.

\bigskip

In fact the overview is already rather obsolete, but the paper is 
instructive because it 
gives some insight into translation problems which are 
typical of Japanese.

\bigskip

To my knowledge there are no publications in English on the systems
LAMB (Canon), PAROLE (Mitsubishi), MELTRAN (Mitsubishi), RMT
(Ricoh), Sharp's MT system. At the MT Summit Conference some information
on these systems was given, which has been copied in section 3.

At this conference, of which the proceedings will be published,
there were also short papers on the systems
ATLAS (Fujitsu), HICATS (Hitachi), TAURUS (Toshiba), MU (Kyoto University)
and PIVOT (NEC).

\bigskip

In general publications in English are scarce, except
for LUTE (NTT) and MU (Kyoto University).


\bigskip

LUTE:


\bigskip

Shimazu A., S. Naito and H. Nomura, {\em Semantic structure
analysis of Japanese Noun Phrases with adnominal particles}.
ACL Conference, Stanford, July 1987.

\bigskip

Nomura H., S. Naito, Y. Katagiri and A. Shimazu, 
{\em Translation by Understanding: A Machine Translation System LUTE}.
Proceedings of COLING 86, Bonn, 1986.

\bigskip

MU:

\bigskip

Nagao M. et al., {\em Transfer phase of a Machine Translation system}.
Proceedings of COLING 86, Bonn, 1986.

\bigskip

Nagao, M., Tsujii, J. and Nakamura, J., {\em The Japanese Government Project of 
Machine Translation}, Journal of Computational Linguistics, vol. 11, No. 2-3,
1985.

\bigskip

ATLAS:

\bigskip

Only one short and informal paper is available.

\bigskip

Uchida, H., {\em Fujitsu Machine Translation System: ATLAS}.
In: Future Generation Computer Systems 2 (1986), pp 95 - 100.

\bigskip

HICATS:

\bigskip

About the actual HICATS system no papers are available. However, it
is based on the experimental system ATHENE, on which several 
publications have been written. 

\bigskip

Nitta, Y. et al., {\em A proper treatment of syntax and semantics in machine
translation}.
Proceedings of COLING 84, Stanford, 1984.

\bigskip

TAURUS:

\bigskip

Amano, S., {\em The Toshiba Machine Translation System}.
In: Future Generations Computer Systems 2 (1986), pp 121 - 123.

\bigskip


PIVOT:

\bigskip

Muraki, K., {\em VENUS: Two-phase machine translation system}.
In: Future Generation Computer Systems 2 (1986), pp 117 - 119.


\bigskip


PENSEE:

\bigskip

Sakamoto, M. and T. Shiino, {\em Japanese-English machine translation system
''PENSEE"}.
OKI Technical Review 126, April 1987.

\end{document}
ROSETTA.sty
\typeout{Document Style 'Rosetta'. Version 0.4 - released  24-DEC-1987}
% 24-DEC-1987:  Date of copyright notice changed
\def\@ptsize{1}
\@namedef{ds@10pt}{\def\@ptsize{0}}
\@namedef{ds@12pt}{\def\@ptsize{2}} 
\@twosidetrue
\@mparswitchtrue
\def\ds@draft{\overfullrule 5pt} 
\@options
\input art1\@ptsize.sty\relax


\def\labelenumi{\arabic{enumi}.} 
\def\theenumi{\arabic{enumi}} 
\def\labelenumii{(\alph{enumii})}
\def\theenumii{\alph{enumii}}
\def\p@enumii{\theenumi}
\def\labelenumiii{\roman{enumiii}.}
\def\theenumiii{\roman{enumiii}}
\def\p@enumiii{\theenumi(\theenumii)}
\def\labelenumiv{\Alph{enumiv}.}
\def\theenumiv{\Alph{enumiv}} 
\def\p@enumiv{\p@enumiii\theenumiii}
\def\labelitemi{$\bullet$}
\def\labelitemii{\bf --}
\def\labelitemiii{$\ast$}
\def\labelitemiv{$\cdot$}
\def\verse{
   \let\\=\@centercr 
   \list{}{\itemsep\z@ \itemindent -1.5em\listparindent \itemindent 
      \rightmargin\leftmargin\advance\leftmargin 1.5em}
   \item[]}
\let\endverse\endlist
\def\quotation{
   \list{}{\listparindent 1.5em
      \itemindent\listparindent
      \rightmargin\leftmargin \parsep 0pt plus 1pt}\item[]}
\let\endquotation=\endlist
\def\quote{
   \list{}{\rightmargin\leftmargin}\item[]}
\let\endquote=\endlist
\def\descriptionlabel#1{\hspace\labelsep \bf #1}
\def\description{
   \list{}{\labelwidth\z@ \itemindent-\leftmargin
      \let\makelabel\descriptionlabel}}
\let\enddescription\endlist


\def\@begintheorem#1#2{\it \trivlist \item[\hskip \labelsep{\bf #1\ #2}]}
\def\@endtheorem{\endtrivlist}
\def\theequation{\arabic{equation}}
\def\titlepage{
   \@restonecolfalse
   \if@twocolumn\@restonecoltrue\onecolumn
   \else \newpage
   \fi
   \thispagestyle{empty}\c@page\z@}
\def\endtitlepage{\if@restonecol\twocolumn \else \newpage \fi}
\arraycolsep 5pt \tabcolsep 6pt \arrayrulewidth .4pt \doublerulesep 2pt 
\tabbingsep \labelsep 
\skip\@mpfootins = \skip\footins
\fboxsep = 3pt \fboxrule = .4pt 


\newcounter{part}
\newcounter {section}
\newcounter {subsection}[section]
\newcounter {subsubsection}[subsection]
\newcounter {paragraph}[subsubsection]
\newcounter {subparagraph}[paragraph]
\def\thepart{\Roman{part}} \def\thesection {\arabic{section}}
\def\thesubsection {\thesection.\arabic{subsection}}
\def\thesubsubsection {\thesubsection .\arabic{subsubsection}}
\def\theparagraph {\thesubsubsection.\arabic{paragraph}}
\def\thesubparagraph {\theparagraph.\arabic{subparagraph}}


\def\@pnumwidth{1.55em}
\def\@tocrmarg {2.55em}
\def\@dotsep{4.5}
\setcounter{tocdepth}{3}
\def\tableofcontents{\section*{Contents\markboth{}{}}
\@starttoc{toc}}
\def\l@part#1#2{
   \addpenalty{-\@highpenalty}
   \addvspace{2.25em plus 1pt}
   \begingroup
      \@tempdima 3em \parindent \z@ \rightskip \@pnumwidth \parfillskip
      -\@pnumwidth {\large \bf \leavevmode #1\hfil \hbox to\@pnumwidth{\hss #2}}
      \par \nobreak
   \endgroup}
\def\l@section#1#2{
   \addpenalty{-\@highpenalty}
   \addvspace{1.0em plus 1pt}
   \@tempdima 1.5em
   \begingroup
      \parindent \z@ \rightskip \@pnumwidth 
      \parfillskip -\@pnumwidth 
      \bf \leavevmode #1\hfil \hbox to\@pnumwidth{\hss #2}
      \par
   \endgroup}
\def\l@subsection{\@dottedtocline{2}{1.5em}{2.3em}}
\def\l@subsubsection{\@dottedtocline{3}{3.8em}{3.2em}}
\def\l@paragraph{\@dottedtocline{4}{7.0em}{4.1em}}
\def\l@subparagraph{\@dottedtocline{5}{10em}{5em}}
\def\listoffigures{
   \section*{List of Figures\markboth{}{}}
   \@starttoc{lof}}
   \def\l@figure{\@dottedtocline{1}{1.5em}{2.3em}}
   \def\listoftables{\section*{List of Tables\markboth{}{}}
   \@starttoc{lot}}
\let\l@table\l@figure


\def\thebibliography#1{
   \addcontentsline{toc}
   {section}{References}\section*{References\markboth{}{}}
   \list{[\arabic{enumi}]}
        {\settowidth\labelwidth{[#1]}\leftmargin\labelwidth
         \advance\leftmargin\labelsep\usecounter{enumi}}}
\let\endthebibliography=\endlist


\newif\if@restonecol
\def\theindex{
   \@restonecoltrue\if@twocolumn\@restonecolfalse\fi
   \columnseprule \z@
   \columnsep 35pt\twocolumn[\section*{Index}]
   \markboth{}{}
   \thispagestyle{plain}\parindent\z@
   \parskip\z@ plus .3pt\relax
   \let\item\@idxitem}
\def\@idxitem{\par\hangindent 40pt}
\def\subitem{\par\hangindent 40pt \hspace*{20pt}}
\def\subsubitem{\par\hangindent 40pt \hspace*{30pt}}
\def\endtheindex{\if@restonecol\onecolumn\else\clearpage\fi}
\def\indexspace{\par \vskip 10pt plus 5pt minus 3pt\relax}


\def\footnoterule{
   \kern-1\p@ 
   \hrule width .4\columnwidth 
   \kern .6\p@} 
\long\def\@makefntext#1{
   \@setpar{\@@par\@tempdima \hsize 
   \advance\@tempdima-10pt\parshape \@ne 10pt \@tempdima}\par
   \parindent 1em\noindent \hbox to \z@{\hss$^{\@thefnmark}$}#1}


\setcounter{topnumber}{2}
\def\topfraction{.7}
\setcounter{bottomnumber}{1}
\def\bottomfraction{.3}
\setcounter{totalnumber}{3}
\def\textfraction{.2}
\def\floatpagefraction{.5}
\setcounter{dbltopnumber}{2}
\def\dbltopfraction{.7}
\def\dblfloatpagefraction{.5}
\long\def\@makecaption#1#2{
   \vskip 10pt 
   \setbox\@tempboxa\hbox{#1: #2}
   \ifdim \wd\@tempboxa >\hsize \unhbox\@tempboxa\par
   \else \hbox to\hsize{\hfil\box\@tempboxa\hfil} 
   \fi}
\newcounter{figure}
\def\thefigure{\@arabic\c@figure}
\def\fps@figure{tbp}
\def\ftype@figure{1}
\def\ext@figure{lof}
\def\fnum@figure{Figure \thefigure}
\def\figure{\@float{figure}}
\let\endfigure\end@float
\@namedef{figure*}{\@dblfloat{figure}}
\@namedef{endfigure*}{\end@dblfloat}
\newcounter{table}
\def\thetable{\@arabic\c@table}
\def\fps@table{tbp}
\def\ftype@table{2}
\def\ext@table{lot}
\def\fnum@table{Table \thetable}
\def\table{\@float{table}}
\let\endtable\end@float
\@namedef{table*}{\@dblfloat{table}}
\@namedef{endtable*}{\end@dblfloat}


\def\maketitle{
   \par
   \begingroup
      \def\thefootnote{\fnsymbol{footnote}}
      \def\@makefnmark{\hbox to 0pt{$^{\@thefnmark}$\hss}} 
      \if@twocolumn \twocolumn[\@maketitle] 
      \else \newpage \global\@topnum\z@ \@maketitle
      \fi
      \thispagestyle{plain}
      \@thanks
   \endgroup
   \setcounter{footnote}{0}
   \let\maketitle\relax
   \let\@maketitle\relax
   \gdef\@thanks{}
   \gdef\@author{}
   \gdef\@title{}
   \let\thanks\relax}
\def\@maketitle{
   \newpage
   \null
   \vskip 2em
   \begin{center}{\LARGE \@title \par}
      \vskip 1.5em
      {\large \lineskip .5em \begin{tabular}[t]{c}\@author \end{tabular}\par} 
      \vskip 1em {\large \@date}
   \end{center}
   \par
   \vskip 1.5em} 
\def\abstract{
   \if@twocolumn \section*{Abstract}
   \else
      \small 
      \begin{center} {\bf Abstract\vspace{-.5em}\vspace{0pt}} \end{center}
      \quotation 
   \fi}
\def\endabstract{\if@twocolumn\else\endquotation\fi}


\mark{{}{}} 
\if@twoside
   \def\ps@headings{
      \def\@oddfoot{Rosetta Doc. \@RosDocNr\hfil \@RosDate}
      \def\@evenfoot{Rosetta Doc. \@RosDocNr\hfil \@RosDate}
      \def\@evenhead{\rm\thepage\hfil \sl \rightmark}
      \def\@oddhead{\hbox{}\sl \leftmark \hfil\rm\thepage}
      \def\sectionmark##1{\markboth {}{}}
      \def\subsectionmark##1{}}
\else
   \def\ps@headings{
      \def\@oddfoot{Rosetta Doc. \@RosDocNr\hfil \@RosDate}
      \def\@evenfoot{Rosetta Doc. \@RosDocNr\hfil \@RosDate}
      \def\@oddhead{\hbox{}\sl \rightmark \hfil \rm\thepage}
      \def\sectionmark##1{\markboth {}{}}
      \def\subsectionmark##1{}}
\fi
\def\ps@myheadings{
   \def\@oddhead{\hbox{}\sl\@rhead \hfil \rm\thepage}
   \def\@oddfoot{}
   \def\@evenhead{\rm \thepage\hfil\sl\@lhead\hbox{}}
   \def\@evenfoot{}
   \def\sectionmark##1{}
   \def\subsectionmark##1{}}


\def\today{
   \ifcase\month\or January\or February\or March\or April\or May\or June\or
      July\or August\or September\or October\or November\or December
   \fi
   \space\number\day, \number\year}


\ps@plain \pagenumbering{arabic} \onecolumn \if@twoside\else\raggedbottom\fi 




% the Rosetta title page
\newcommand{\MakeRosTitle}{
   \begin{titlepage}
      \begin{large}
	 \begin{figure}[t]
	    \begin{picture}(405,100)(0,0)
	       \put(0,100){\line(1,0){404}}
	       \put(0,75){Project {\bf Rosetta}}
	       \put(93.5,75){:}
	       \put(108,75){Machine Translation}
	       \put(0,50){Topic}
	       \put(93.5,50){:}
	       \put(108,50){\@RosTopic}
	       \put(0,30){\line(1,0){404}}
	    \end{picture}
	 \end{figure}
	 \bigskip
	 \bigskip
	 \begin{list}{-}{\setlength{\leftmargin}{3.0cm}
			 \setlength{\labelwidth}{2.7cm}
			 \setlength{\topsep}{2cm}}
	    \item [{\rm Title \hfill :}] {{\bf \@RosTitle}}
	    \item [{\rm Author \hfill :}] {\@RosAuthor}
	    \bigskip
	    \bigskip
	    \bigskip
	    \item [{\rm Doc.Nr. \hfill :}] {\@RosDocNr}
	    \item [{\rm Date \hfill :}] {\@RosDate}
	    \item [{\rm Status \hfill :}] {\@RosStatus}
	    \item [{\rm Supersedes \hfill :}] {\@RosSupersedes}
	    \item [{\rm Distribution \hfill :}] {\@RosDistribution}
	    \item [{\rm Clearance \hfill :}] {\@RosClearance}
	    \item [{\rm Keywords \hfill :}] {\@RosKeywords}
	 \end{list}
      \end{large}
      \title{\@RosTitle}
      \begin{figure}[b]
	 \begin{picture}(404,64)(0,0)
	    \put(0,64){\line(1,0){404}}
	    \put(0,-4){\line(1,0){404}}
	    \put(0,59){\line(1,0){42}}
	    \begin{small}
	    \put(3,48){\sf PHILIPS}
	    \end{small}
	    \put(0,23){\line(0,1){36}}
	    \put(42,23){\line(0,1){36}}
	    \put(21,23){\oval(42,42)[bl]}
	    \put(21,23){\oval(42,42)[br]}
	    \put(21,23){\circle{40}}
	    \put(4,33){\line(1,0){10}}
	    \put(9,28){\line(0,1){10}}
	    \put(9,36){\line(1,0){6}}
	    \put(12,33){\line(0,1){6}}
	    \put(29,13){\line(1,0){10}}
	    \put(34,8){\line(0,1){10}}
	    \put(28,10){\line(1,0){6}}
	    \put(31,7){\line(0,1){6}}

	    \put(1,21){\line(1,0){0.5}}
	    \put(1.5,21.3){\line(1,0){0.5}}
	    \put(2,21.6){\line(1,0){0.5}}
	    \put(2.5,21.9){\line(1,0){0.5}}
	    \put(3,22.1){\line(1,0){0.5}}
	    \put(3.5,22.3){\line(1,0){0.5}}
	    \put(4,22.5){\line(1,0){0.5}}
	    \put(4.5,22.7){\line(1,0){0.5}}
	    \put(5,22.8){\line(1,0){0.5}}
	    \put(5.5,22.9){\line(1,0){0.5}}
	    \put(6,23){\line(1,0){0.5}}
	    \put(6.5,22.9){\line(1,0){0.5}}
	    \put(7,22.8){\line(1,0){0.5}}
	    \put(7.5,22.7){\line(1,0){0.5}}
	    \put(8,22.5){\line(1,0){0.5}}
	    \put(8.5,22.3){\line(1,0){0.5}}
	    \put(9,22.1){\line(1,0){0.5}}
	    \put(9.5,21.9){\line(1,0){0.5}}
	    \put(10,21.6){\line(1,0){0.5}}
	    \put(10.5,21.3){\line(1,0){0.5}}

	    \put(1,23){\line(1,0){0.5}}
	    \put(1.5,23.3){\line(1,0){0.5}}
	    \put(2,23.6){\line(1,0){0.5}}
	    \put(2.5,23.9){\line(1,0){0.5}}
	    \put(3,24.1){\line(1,0){0.5}}
	    \put(3.5,24.3){\line(1,0){0.5}}
	    \put(4,24.5){\line(1,0){0.5}}
	    \put(4.5,24.7){\line(1,0){0.5}}
	    \put(5,24.8){\line(1,0){0.5}}
	    \put(5.5,24.9){\line(1,0){0.5}}
	    \put(6,25){\line(1,0){0.5}}
	    \put(6.5,24.9){\line(1,0){0.5}}
	    \put(7,24.8){\line(1,0){0.5}}
	    \put(7.5,24.7){\line(1,0){0.5}}
	    \put(8,24.5){\line(1,0){0.5}}
	    \put(8.5,24.3){\line(1,0){0.5}}
	    \put(9,24.1){\line(1,0){0.5}}
	    \put(9.5,23.9){\line(1,0){0.5}}
	    \put(10,23.6){\line(1,0){0.5}}
	    \put(10.5,23.3){\line(1,0){0.5}}

	    \put(1,25){\line(1,0){0.5}}
	    \put(1.5,25.3){\line(1,0){0.5}}
	    \put(2,25.6){\line(1,0){0.5}}
	    \put(2.5,25.9){\line(1,0){0.5}}
	    \put(3,26.1){\line(1,0){0.5}}
	    \put(3.5,26.3){\line(1,0){0.5}}
	    \put(4,26.5){\line(1,0){0.5}}
	    \put(4.5,26.7){\line(1,0){0.5}}
	    \put(5,26.8){\line(1,0){0.5}}
	    \put(5.5,26.9){\line(1,0){0.5}}
	    \put(6,27){\line(1,0){0.5}}
	    \put(6.5,26.9){\line(1,0){0.5}}
	    \put(7,26.8){\line(1,0){0.5}}
	    \put(7.5,26.7){\line(1,0){0.5}}
	    \put(8,26.5){\line(1,0){0.5}}
	    \put(8.5,26.3){\line(1,0){0.5}}
	    \put(9,26.1){\line(1,0){0.5}}
	    \put(9.5,25.9){\line(1,0){0.5}}
	    \put(10,25.6){\line(1,0){0.5}}
	    \put(10.5,25.3){\line(1,0){0.5}}

	    \put(11,21){\line(1,0){0.5}}
	    \put(11.5,20.7){\line(1,0){0.5}}
	    \put(12,20.4){\line(1,0){0.5}}
	    \put(12.5,20.1){\line(1,0){0.5}}
	    \put(13,19.9){\line(1,0){0.5}}
	    \put(13.5,19.7){\line(1,0){0.5}}
	    \put(14,19.5){\line(1,0){0.5}}
	    \put(14.5,19.3){\line(1,0){0.5}}
	    \put(15,19.2){\line(1,0){0.5}}
	    \put(15.5,19.1){\line(1,0){0.5}}
	    \put(16,19){\line(1,0){0.5}}
	    \put(16.5,19.1){\line(1,0){0.5}}
	    \put(17,19.2){\line(1,0){0.5}}
	    \put(17.5,19.3){\line(1,0){0.5}}
	    \put(18,19.5){\line(1,0){0.5}}
	    \put(18.5,19.7){\line(1,0){0.5}}
	    \put(19,19.9){\line(1,0){0.5}}
	    \put(19.5,20.1){\line(1,0){0.5}}
	    \put(20,20.4){\line(1,0){0.5}}
	    \put(20.5,20.7){\line(1,0){0.5}}

	    \put(11,23){\line(1,0){0.5}}
	    \put(11.5,22.7){\line(1,0){0.5}}
	    \put(12,22.4){\line(1,0){0.5}}
	    \put(12.5,22.1){\line(1,0){0.5}}
	    \put(13,21.9){\line(1,0){0.5}}
	    \put(13.5,21.7){\line(1,0){0.5}}
	    \put(14,21.5){\line(1,0){0.5}}
	    \put(14.5,21.3){\line(1,0){0.5}}
	    \put(15,21.2){\line(1,0){0.5}}
	    \put(15.5,21.1){\line(1,0){0.5}}
	    \put(16,21){\line(1,0){0.5}}
	    \put(16.5,21.1){\line(1,0){0.5}}
	    \put(17,21.2){\line(1,0){0.5}}
	    \put(17.5,21.3){\line(1,0){0.5}}
	    \put(18,21.5){\line(1,0){0.5}}
	    \put(18.5,21.7){\line(1,0){0.5}}
	    \put(19,21.9){\line(1,0){0.5}}
	    \put(19.5,22.1){\line(1,0){0.5}}
	    \put(20,22.4){\line(1,0){0.5}}
	    \put(20.5,22.7){\line(1,0){0.5}}

	    \put(11,25){\line(1,0){0.5}}
	    \put(11.5,24.7){\line(1,0){0.5}}
	    \put(12,24.4){\line(1,0){0.5}}
	    \put(12.5,24.1){\line(1,0){0.5}}
	    \put(13,23.9){\line(1,0){0.5}}
	    \put(13.5,23.7){\line(1,0){0.5}}
	    \put(14,23.5){\line(1,0){0.5}}
	    \put(14.5,23.3){\line(1,0){0.5}}
	    \put(15,23.2){\line(1,0){0.5}}
	    \put(15.5,23.1){\line(1,0){0.5}}
	    \put(16,23){\line(1,0){0.5}}
	    \put(16.5,23.1){\line(1,0){0.5}}
	    \put(17,23.2){\line(1,0){0.5}}
	    \put(17.5,23.3){\line(1,0){0.5}}
	    \put(18,23.5){\line(1,0){0.5}}
	    \put(18.5,23.7){\line(1,0){0.5}}
	    \put(19,23.9){\line(1,0){0.5}}
	    \put(19.5,24.1){\line(1,0){0.5}}
	    \put(20,24.4){\line(1,0){0.5}}
	    \put(20.5,24.7){\line(1,0){0.5}}

	    \put(21,21){\line(1,0){0.5}}
	    \put(21.5,21.3){\line(1,0){0.5}}
	    \put(22,21.6){\line(1,0){0.5}}
	    \put(22.5,21.9){\line(1,0){0.5}}
	    \put(23,22.1){\line(1,0){0.5}}
	    \put(23.5,22.3){\line(1,0){0.5}}
	    \put(24,22.5){\line(1,0){0.5}}
	    \put(24.5,22.7){\line(1,0){0.5}}
	    \put(25,22.8){\line(1,0){0.5}}
	    \put(25.5,23.9){\line(1,0){0.5}}
	    \put(26,23){\line(1,0){0.5}}
	    \put(26.5,22.9){\line(1,0){0.5}}
	    \put(27,22.8){\line(1,0){0.5}}
	    \put(27.5,22.7){\line(1,0){0.5}}
	    \put(28,22.5){\line(1,0){0.5}}
	    \put(28.5,22.3){\line(1,0){0.5}}
	    \put(29,22.1){\line(1,0){0.5}}
	    \put(29.5,21.9){\line(1,0){0.5}}
	    \put(30,21.6){\line(1,0){0.5}}
	    \put(30.5,21.3){\line(1,0){0.5}}

	    \put(21,23){\line(1,0){0.5}}
	    \put(21.5,23.3){\line(1,0){0.5}}
	    \put(22,23.6){\line(1,0){0.5}}
	    \put(22.5,23.9){\line(1,0){0.5}}
	    \put(23,24.1){\line(1,0){0.5}}
	    \put(23.5,24.3){\line(1,0){0.5}}
	    \put(24,24.5){\line(1,0){0.5}}
	    \put(24.5,24.7){\line(1,0){0.5}}
	    \put(25,24.8){\line(1,0){0.5}}
	    \put(25.5,24.9){\line(1,0){0.5}}
	    \put(26,25){\line(1,0){0.5}}
	    \put(26.5,24.9){\line(1,0){0.5}}
	    \put(27,24.8){\line(1,0){0.5}}
	    \put(27.5,24.7){\line(1,0){0.5}}
	    \put(28,24.5){\line(1,0){0.5}}
	    \put(28.5,24.3){\line(1,0){0.5}}
	    \put(29,24.1){\line(1,0){0.5}}
	    \put(29.5,23.9){\line(1,0){0.5}}
	    \put(30,23.6){\line(1,0){0.5}}
	    \put(30.5,23.3){\line(1,0){0.5}}

	    \put(21,25){\line(1,0){0.5}}
	    \put(21.5,25.3){\line(1,0){0.5}}
	    \put(22,25.6){\line(1,0){0.5}}
	    \put(22.5,25.9){\line(1,0){0.5}}
	    \put(23,26.1){\line(1,0){0.5}}
	    \put(23.5,26.3){\line(1,0){0.5}}
	    \put(24,26.5){\line(1,0){0.5}}
	    \put(24.5,26.7){\line(1,0){0.5}}
	    \put(25,26.8){\line(1,0){0.5}}
	    \put(25.5,26.9){\line(1,0){0.5}}
	    \put(26,27){\line(1,0){0.5}}
	    \put(26.5,26.9){\line(1,0){0.5}}
	    \put(27,26.8){\line(1,0){0.5}}
	    \put(27.5,26.7){\line(1,0){0.5}}
	    \put(28,26.5){\line(1,0){0.5}}
	    \put(28.5,26.3){\line(1,0){0.5}}
	    \put(29,26.1){\line(1,0){0.5}}
	    \put(29.5,25.9){\line(1,0){0.5}}
	    \put(30,25.6){\line(1,0){0.5}}
	    \put(30.5,25.3){\line(1,0){0.5}}

	    \put(31,21){\line(1,0){0.5}}
	    \put(31.5,20.7){\line(1,0){0.5}}
	    \put(32,20.4){\line(1,0){0.5}}
	    \put(32.5,20.1){\line(1,0){0.5}}
	    \put(33,19.9){\line(1,0){0.5}}
	    \put(33.5,19.7){\line(1,0){0.5}}
	    \put(34,19.5){\line(1,0){0.5}}
	    \put(34.5,19.3){\line(1,0){0.5}}
	    \put(35,19.2){\line(1,0){0.5}}
	    \put(35.5,19.1){\line(1,0){0.5}}
	    \put(36,19){\line(1,0){0.5}}
	    \put(36.5,19.1){\line(1,0){0.5}}
	    \put(37,19.2){\line(1,0){0.5}}
	    \put(37.5,19.3){\line(1,0){0.5}}
	    \put(38,19.5){\line(1,0){0.5}}
	    \put(38.5,19.7){\line(1,0){0.5}}
	    \put(39,19.9){\line(1,0){0.5}}
	    \put(39.5,20.1){\line(1,0){0.5}}
	    \put(40,20.4){\line(1,0){0.5}}
	    \put(40.5,20.7){\line(1,0){0.5}}

	    \put(31,23){\line(1,0){0.5}}
	    \put(31.5,22.7){\line(1,0){0.5}}
	    \put(32,22.4){\line(1,0){0.5}}
	    \put(32.5,22.1){\line(1,0){0.5}}
	    \put(33,21.9){\line(1,0){0.5}}
	    \put(33.5,21.7){\line(1,0){0.5}}
	    \put(34,21.5){\line(1,0){0.5}}
	    \put(34.5,21.3){\line(1,0){0.5}}
	    \put(35,21.2){\line(1,0){0.5}}
	    \put(35.5,21.1){\line(1,0){0.5}}
	    \put(36,21){\line(1,0){0.5}}
	    \put(36.5,21.1){\line(1,0){0.5}}
	    \put(37,21.2){\line(1,0){0.5}}
	    \put(37.5,21.3){\line(1,0){0.5}}
	    \put(38,21.5){\line(1,0){0.5}}
	    \put(38.5,21.7){\line(1,0){0.5}}
	    \put(39,21.9){\line(1,0){0.5}}
	    \put(39.5,22.1){\line(1,0){0.5}}
	    \put(40,22.4){\line(1,0){0.5}}
	    \put(40.5,22.7){\line(1,0){0.5}}

	    \put(31,25){\line(1,0){0.5}}
	    \put(31.5,24.7){\line(1,0){0.5}}
	    \put(32,24.4){\line(1,0){0.5}}
	    \put(32.5,24.1){\line(1,0){0.5}}
	    \put(33,23.9){\line(1,0){0.5}}
	    \put(33.5,23.7){\line(1,0){0.5}}
	    \put(34,23.5){\line(1,0){0.5}}
	    \put(34.5,23.3){\line(1,0){0.5}}
	    \put(35,23.2){\line(1,0){0.5}}
	    \put(35.5,23.1){\line(1,0){0.5}}
	    \put(36,23){\line(1,0){0.5}}
	    \put(36.5,23.1){\line(1,0){0.5}}
	    \put(37,23.2){\line(1,0){0.5}}
	    \put(37.5,23.3){\line(1,0){0.5}}
	    \put(38,23.5){\line(1,0){0.5}}
	    \put(38.5,23.7){\line(1,0){0.5}}
	    \put(39,23.9){\line(1,0){0.5}}
	    \put(39.5,24.1){\line(1,0){0.5}}
	    \put(40,24.4){\line(1,0){0.5}}
	    \put(40.5,24.7){\line(1,0){0.5}}
	    \begin{large}
	       \put(60,45){Philips Research Laboratories}
	       \put(60,30){\copyright\ 1988 Nederlandse Philips Bedrijven B.V.}
	    \end{large}
	 \end{picture}
      \end{figure}
      \newpage
      \pagenumbering{roman}
      \tableofcontents
      \newpage
      \pagenumbering{arabic}
   \end{titlepage}
}
\title{}
\topmargin 0pt
\oddsidemargin 36pt
\evensidemargin 36pt
\textheight 600pt
\textwidth 405pt
\pagestyle{headings}
\newcommand{\@RosTopic}{General}
\newcommand{\@RosTitle}{-}
\newcommand{\@RosAuthor}{-}
\newcommand{\@RosDocNr}{}
\newcommand{\@RosDate}{\today}
\newcommand{\@RosStatus}{informal}
\newcommand{\@RosSupersedes}{-}
\newcommand{\@RosDistribution}{Project}
\newcommand{\@RosClearance}{Project}
\newcommand{\@RosKeywords}{}
\newcommand{\RosTopic}[1]{\renewcommand{\@RosTopic}{#1}}
\newcommand{\RosTitle}[1]{\renewcommand{\@RosTitle}{#1}}
\newcommand{\RosAuthor}[1]{\renewcommand{\@RosAuthor}{#1}}
\newcommand{\RosDocNr}[1]{\renewcommand{\@RosDocNr}{#1}}
\newcommand{\RosDate}[1]{\renewcommand{\@RosDate}{#1}}
\newcommand{\RosStatus}[1]{\renewcommand{\@RosStatus}{#1}}
\newcommand{\RosSupersedes}[1]{\renewcommand{\@RosSupersedes}{#1}}
\newcommand{\RosDistribution}[1]{\renewcommand{\@RosDistribution}{#1}}
\newcommand{\RosClearance}[1]{\renewcommand{\@RosClearance}{#1}}
\newcommand{\RosKeywords}[1]{\renewcommand{\@RosKeywords}{#1}}

